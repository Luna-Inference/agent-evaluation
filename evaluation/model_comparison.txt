MODEL COMPARISON SUMMARY
================================================================================

Model Performance Metrics:
--------------------------------------------------------------------------------
Model                     Tasks  Correct %  Steps    Failures   Misund.  Tokens     Time (s)  
--------------------------------------------------------------------------------
log09 - phi4              98     87.2%      2.4    0.1        0.0      0.0     184.8
log07 - qwen3:14b         7      78.6%      2.0    0.0        0.0      0.0     202.7
log11 - o3-mini           183    72.1%      1.1    0.4        0.0      0.0     5.8
log02 - qwen3:1.7b        23     65.2%      2.1    0.1        0.0      0.0     172.7
log15 - gpt-4.1           183    60.4%      2.3    0.6        0.0      0.0     5.4
log12 - gpt4.1            183    59.0%      2.4    0.6        0.0      0.0     5.3
log10 - phi4-reasoning    58     50.9%      5.3    7.0        0.1      0.0     1862.5
log08 - dria-agent-alpha-3b 9      50.0%      8.0    4.9        0.8      0.0     156.6
log04 - qwen3:1.7b        182    46.7%      2.3    0.2        0.0      0.0     39.8
log03 - qwen3:1.7b        612    44.9%      2.5    0.5        0.0      0.0     44.4
log05 - qwen3:1.7b        16     43.8%      2.4    0.1        0.1      0.0     42.4
log30 - qwen3:1.7b        97     43.3%      4.1    1.1        0.0      0.0     61.3
log19 - mistral           24     29.2%      9.1    3.1        0.1      0.0     884.9
log11 - phi4-mini         4      25.0%      5.8    5.0        5.0      0.0     4328.6
log20 - qwen2.5:0.5b      36     20.8%      14.0    11.0        0.6      0.0     76.8
log31 - olmo2-1b          5      20.0%      0.8    0.0        0.0      0.0     4.7
log25 - qwen2.5:1.5b      116    15.5%      11.1    5.9        0.0      0.0     190.0
log27 - llama3.2:3b       183    15.3%      11.1    5.0        0.0      0.0     381.9
log29 - qwen2.5-coder:1.5b 183    13.1%      14.3    7.9        0.0      0.0     284.1
log13 - sonar-pro         183    11.5%      1.7    9.7        0.0      0.0     10.8
log22 - llama3.2:1b       18     5.6%      18.0    10.1        0.1      0.0     1231.1
log21 - qwen2.5:0.5b      18     5.6%      15.6    9.1        0.2      0.0     422.3
log24 - qwen2.5:0.5b      183    5.5%      15.8    13.0        0.1      0.0     222.8
log23 - llama3.2:1b       127    3.9%      15.9    13.5        0.0      0.0     1335.8
log06 - gemma3:1b         2      0.0%      18.5    1.0        0.5      0.0     83.4
log16 - deepseek-r1:1.5b  1      0.0%      14.0    0.0        0.0      0.0     526.5
log11 - phi4-mini-reasoning 1      0.0%      20.0    7.0        0.0      0.0     7009.5
log17 - deepseek-r1:7b    1      0.0%      15.0    1.0        0.0      0.0     636.7
log18 - osmosis           1      0.0%      4.0    3.0        0.0      1456.0     706.3
log26 - llama3.2:3b       18     0.0%      1.0    7.7        0.1      0.0     0.1
log28 - qwen2.5-coder:0.5b 1      0.0%      15.0    6.0        0.0      0.0     114.6
log32 - starcoder         14     0.0%      18.6    6.1        0.0      445.4     146.0
